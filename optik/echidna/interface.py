from maat import Cst, EVMTransaction, Value, Var, VarContext
from typing import Dict, Final, List, Optional, Tuple, Union, Any
from ..common.exceptions import EchidnaException, GenericException
from ..common.abi import function_call
from ..common.logger import logger
from ..common.world import AbstractTx
from ..common.util import (
    twos_complement_convert,
    int_to_bool,
    echidna_parse_bytes,
    echidna_encode_bytes,
)

import os
import json
import tempfile

# Prefix for files containing new inputs generated by the symbolic executor
NEW_INPUT_PREFIX: Final[str] = "optik_solved_input"


def translate_argument_type(arg: Dict) -> str:
    """Translates a serialized argument's type into a string"""
    t = arg["tag"]
    if t == "AbiUInt":
        bits = arg["contents"][0]
        return f"uint{bits}"

    elif t == "AbiUIntType":
        bits = arg["contents"]
        return f"uint{bits}"

    elif t == "AbiInt":
        bits = arg["contents"][0]
        return f"int{bits}"

    elif t == "AbiIntType":
        bits = arg["contents"]
        return f"int{bits}"

    elif t.startswith("AbiAddress"):
        return "address"

    elif t == "AbiBytes":
        byteLen = arg["contents"][0]
        return f"bytes{byteLen}"

    elif t == "AbiBytesType":
        byteLen = arg["contents"]
        return f"bytes{byteLen}"

    elif t.startswith("AbiString"):
        return "string"

    elif t.startswith("AbiBytesDynamic"):
        return f"bytes"

    elif t.startswith("AbiBool"):
        return "bool"

    elif t == "AbiArrayDynamic":
        el_type = translate_argument_type(arg["contents"][0])
        return f"{el_type}[]"

    elif t == "AbiArrayDynamicType":
        el_type = translate_argument_type(arg["contents"])
        return f"{el_type}[]"

    elif t.startswith("AbiArray"):
        num_elems = arg["contents"][0]
        el_type = translate_argument_type(arg["contents"][1])
        return f"{el_type}[{num_elems}]"

    elif t.startswith("AbiTuple"):
        contents = arg["contents"]
        types = [translate_argument_type(el) for el in contents]
        return f"({','.join(types)})"

    else:
        raise EchidnaException(f"Unsupported argument type: {t}")


def translate_argument_value(arg: Dict) -> Union[bytes, int, Value]:
    """Translate a serialized argument into a python value"""
    t = arg["tag"]
    if t == "AbiUInt":
        return int(arg["contents"][1])

    elif t == "AbiInt":
        return int(arg["contents"][1])

    elif t == "AbiAddress":
        return int(arg["contents"], 16)

    elif t == "AbiBytes":
        return echidna_parse_bytes(arg["contents"][1])

    elif t == "AbiString":
        return echidna_parse_bytes(arg["contents"])

    elif t == "AbiBool":
        return arg["contents"]

    elif t == "AbiBytesDynamic":
        return echidna_parse_bytes(arg["contents"])

    elif t == "AbiArray":
        array = arg["contents"][2]
        return [translate_argument_value(el) for el in array]

    elif t == "AbiArrayDynamic":
        array = arg["contents"][1]
        return [translate_argument_value(el) for el in array]

    elif t == "AbiTuple":
        contents = arg["contents"]
        return [translate_argument_value(el) for el in contents]

    else:
        raise EchidnaException(f"Unsupported argument type: {t}")


def translate_argument(arg: Dict) -> Tuple[str, Union[bytes, int, Value]]:
    """Translate a parsed Echidna transaction argument into a '(type, value)' tuple.
    :param arg: Transaction argument parsed as a json dict
    """

    return (
        translate_argument_type(arg),
        translate_argument_value(arg),
    )


def extract_func_from_call(call: Dict) -> Tuple[str, str, List]:
    """Extract function name, argument spec, and values, from a JSON
    serialized Echidna transaction

    :param call: Call from Echidna transaction
    """
    if call["tag"] != "SolCall":
        raise EchidnaException(f"Unsupported transaction tag: '{call['tag']}'")

    arg_types = []
    arg_values = []
    func_name: str = call["contents"][0]
    if len(call["contents"]) > 1:
        for arg in call["contents"][1]:
            t, val = translate_argument(arg)
            arg_types.append(t)
            arg_values.append(val)

    args_spec = f"({','.join(arg_types)})"

    return func_name, args_spec, arg_values


def load_tx(tx: Dict, tx_name: str = "") -> AbstractTx:
    """Translates a parsed echidna transaction into a Maat transaction

    :param tx: Echidna transaction parsed as a json dict
    :param tx_name: Optional name identifying this transaction, used to
        name symbolic variables created to fill the transaction data
    """
    func_name, args_spec, arg_values = extract_func_from_call(tx["_call"])
    ctx = VarContext()
    call_data = function_call(func_name, args_spec, ctx, tx_name, *arg_values)

    # Translate block number/timestamp increments
    block_num_inc = Var(256, f"{tx_name}_block_num_inc")
    block_timestamp_inc = Var(256, f"{tx_name}_block_timestamp_inc")
    ctx.set(block_num_inc.name, int(tx["_delay"][1], 16), block_num_inc.size)
    ctx.set(
        block_timestamp_inc.name, int(tx["_delay"][0], 16), block_num_inc.size
    )

    # Translate message sender
    sender = Var(160, f"{tx_name}_sender")
    ctx.set(sender.name, int(tx["_src"], 16), sender.size)

    # Translate message value
    value = Var(256, f"{tx_name}_value")
    ctx.set(value.name, int(tx["_value"], 16), value.size)

    # Build transaction
    # TODO: make EVMTransaction accept integers as arguments
    gas_limit = Cst(256, int(tx["_gas'"], 16))
    gas_price = Cst(256, int(tx["_gasprice'"], 16))
    recipient = int(tx["_dst"], 16)
    return AbstractTx(
        EVMTransaction(
            sender,  # origin
            sender,  # sender
            recipient,  # recipient
            value,  # value
            call_data,  # data
            gas_price,  # gas price
            gas_limit,  # gas_limit
        ),
        block_num_inc,
        block_timestamp_inc,
        ctx,
    )


def load_tx_sequence(filename: str) -> List[AbstractTx]:
    """Load a sequence of transactions from an Echidna corpus file

    :param filename: corpus file to load
    """
    with open(filename, "rb") as f:
        data = json.loads(f.read())
        res = []
        for i, tx in enumerate(data):
            res.append(load_tx(tx, tx_name=f"tx{i}"))
        return res


def update_argument(arg: Dict, arg_name: str, new_model: VarContext) -> None:
    """Update an argument value in a transaction according to a
    symbolic model. The argument is modified **in-place**

    :param arg: argument to update, parsed as a JSON dict
    :param arg_name: base name of the symbolic variable that was created for this
    argument
    :param new_model: symbolic model to use to update the argument value
    """

    def is_array_like_type(arg_type: str) -> bool:
        """Return True if encoding the type results in multiple variables,
        i.e arg_0, arg_1, ... arg_N"""
        return any(
            [x for x in ["Tuple", "Array", "Bytes", "String"] if x in arg_type]
        )

    def _update_bytes_like_argument(
        arg_name: str,
        length: int,
        val: List,
        new_model: VarContext,
    ) -> None:
        """Update bytes-like object (bytes, string, dynamic bytes, ...)"""
        for i in range(length):
            byte_name = f"{arg_name}_{i}"
            if new_model.contains(byte_name):
                val[i] = new_model.get(byte_name) & 0xFF

    argType = arg["tag"]

    # Update the argument only if the model contains a new value
    # for this argument
    if is_array_like_type(argType) and all(
        [arg_name not in var for var in new_model.contained_vars()]
    ):
        return
    elif not is_array_like_type(argType) and not new_model.contains(arg_name):
        return

    if argType == "AbiUInt":
        arg["contents"][1] = str(new_model.get(arg_name))

    elif argType == "AbiInt":
        argVal = int(new_model.get(arg_name))
        bits = arg["contents"][0]
        arg["contents"][1] = str(twos_complement_convert(argVal, bits))

    elif argType == "AbiBool":
        argVal = new_model.get(arg_name)
        arg["contents"] = int_to_bool(argVal)

    elif argType == "AbiAddress":
        arg["contents"] = str(hex(new_model.get(arg_name)))

    elif argType == "AbiBytes":
        length = arg["contents"][0]
        val = echidna_parse_bytes(arg["contents"][1])
        _update_bytes_like_argument(arg_name, length, val, new_model)
        arg["contents"][1] = echidna_encode_bytes(val)

    elif argType in ["AbiBytesDynamic", "AbiString"]:
        val = echidna_parse_bytes(arg["contents"])
        _update_bytes_like_argument(arg_name, len(val), val, new_model)
        arg["contents"] = echidna_encode_bytes(val)

    elif argType == "AbiTuple":
        tuple_els = arg["contents"]
        for i, el in enumerate(tuple_els):
            sub_arg_name = f"{arg_name}_{i}"
            update_argument(el, sub_arg_name, new_model)

    elif argType == "AbiArray":
        arr_els = arg["contents"][2]
        for i, el in enumerate(arr_els):
            sub_arg_name = f"{arg_name}_{i}"
            update_argument(el, sub_arg_name, new_model)

    elif argType == "AbiArrayDynamic":
        arr_els = arg["contents"][1]
        for i, el in enumerate(arr_els):
            sub_arg_name = f"{arg_name}_{i}"
            update_argument(el, sub_arg_name, new_model)

    else:
        raise EchidnaException(f"Unsupported argument type: {argType}")


def update_tx(tx: Dict, new_model: VarContext, tx_name: str = "") -> Dict:
    """Update parameter values in a transaction according to a
    symbolic model

    :param tx: Echidna transaction to update, parsed as a JSON dict
    :param new_model: symbolic model to use to update transaction data in 'tx'
    :param tx_name: Optional name identifying the transaction to update, used to
        name get symbolci variables corresponding to the transaction data. Needs
        to match the 'tx_name' passed to load_tx() earlier
    :return: the updated transaction as a JSON dict
    """
    tx = tx.copy()  # Copy transaction to avoid in-place modifications

    # Update call arguments
    call = tx["_call"]
    args = call["contents"][1]
    for i, arg in enumerate(args):
        update_argument(arg, f"{tx_name}_arg{i}", new_model)

    # Update block number & timestamp
    block_num_inc = f"{tx_name}_block_num_inc"
    block_timestamp_inc = f"{tx_name}_block_timestamp_inc"
    if new_model.contains(block_num_inc):
        tx["_delay"][1] = hex(new_model.get(block_num_inc))
    if new_model.contains(block_timestamp_inc):
        tx["_delay"][0] = hex(new_model.get(block_timestamp_inc))

    # Update sender
    sender = f"{tx_name}_sender"
    if new_model.contains(sender):
        # Address so we need to pad it to 40 chars (20bytes)
        tx["_src"] = f"0x{new_model.get(sender):0{40}x}"

    # Update transaction value
    value = f"{tx_name}_value"
    if new_model.contains(value):
        tx["_value"] = hex(new_model.get(value))

    return tx


def store_new_tx_sequence(original_file: str, new_model: VarContext) -> None:
    """Store a new sequence of transactions into a new Echidna corpus file

    :param original_file: path to the file containing the original transaction sequence
    that was replayed in order to find the new input
    :param new_model: symbolic context containing new values for the transaction data
    """
    # Load original JSON corpus input
    with open(original_file, "rb") as f:
        data = json.loads(f.read())

    # Update JSON with new transactions
    new_data = []
    for i, tx in enumerate(data):
        new_data.append(update_tx(tx, new_model, tx_name=f"tx{i}"))

    # Write new corpus input in a fresh file
    new_file = get_available_filename(
        f"{os.path.dirname(original_file)}/{NEW_INPUT_PREFIX}", ".txt"
    )
    with open(new_file, "w") as f:
        json.dump(new_data, f)


def get_available_filename(prefix: str, suffix: str) -> str:
    """Get an avaialble filename. The filename will have the
    form '<prefix>_<num><suffix>' where <num> is automatically
    generated based on existing files

    :param prefix: the new file prefix, including potential absolute the path
    :param suffix: the new file suffix
    """
    num = 0
    num_max = 100000
    while os.path.exists(f"{prefix}_{num}{suffix}") and num < num_max:
        num += 1
    if num >= num_max:
        raise GenericException("Can't find available filename, very odd")
    return f"{prefix}_{num}{suffix}"


def extract_contract_bytecode(
    crytic_dir: str, contract_name: Optional[str]
) -> Optional[str]:
    """Parse compilation information from crytic, extracts the bytecodes
    of compiled contracts, and stores them into separate files.

    :param crytic-dir: the "crytic-export" dir created by echidna after a campaign
    :param contract_name: the name of the contract to extract
    :return: path to a file containing the bytecode for 'contract', or None on failure
    """

    def _name_from_path(path):
        return path.split(":")[-1]

    res = {}
    solc_file = str(os.path.join(crytic_dir, "combined_solc.json"))
    with open(solc_file, "rb") as f:
        data = json.loads(f.read())
        contract_key = None
        all_contracts = data["contracts"]
        all_contract_names = ",".join(iter(all_contracts))
        if contract_name is None:
            if len(all_contracts) == 1:
                contract_name = _name_from_path(next(iter(all_contracts)))
            else:
                logger.error(
                    f"Please specify the target contract among: {all_contract_names}"
                )
                return None

        for contract_path, contract_data in data["contracts"].items():
            if contract_name == _name_from_path(contract_path):
                bytecode = contract_data["bin"]
                output_file: str = tempfile.NamedTemporaryFile(
                    prefix="optik_contract_",
                    suffix=".sol",
                    delete=False,
                ).name
                with open(output_file, "w") as f2:
                    logger.debug(
                        f"Bytecode for contract {contract_name} written in {output_file}"
                    )
                    f2.write(bytecode)
                return output_file

        # Didn't find contract
        logger.fatal(
            f"Couldn't find bytecode for contract {contract_name} in {solc_file}. "
            f"Available contracts: {all_contract_names}"
        )
        return None


def extract_cases_from_json_output(output: str) -> List[List[str]]:
    """TODO doc"""
    # Sometimes the JSON output starts with a line such as
    # "Loaded total of 500 transactions from /tmp/c4/coverage"
    if output.startswith("Loaded total of"):
        output = output.split("\n", 1)[1]
    data = json.loads(output)
    if "tests" not in data:
        return []
    res = []
    for test in data["tests"]:
        if test["status"] == "solved":
            case = []
            for tx in test["transactions"]:
                case.append(
                    f"{tx['function']}({','.join([arg for arg in tx['arguments']])})"
                )
            res.append(case)
            logger.debug(f"DEBUG found test {case}")
        else:
            pass  # TODO: show cases not yet solved???
    return res
