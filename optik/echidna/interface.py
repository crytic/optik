from maat import Cst, EVMTransaction, Value, Var, VarContext
from typing import Dict, Final, List, Tuple, Union
from ..common.exceptions import EchidnaException, GenericException
from ..common.abi import function_call
from ..common.logger import logger
from ..common.world import AbstractTx
from ..common.util import twos_complement_convert, int_to_bool

import os
import json
import random


# Prefix for files containing new inputs generated by the symbolic executor
NEW_INPUT_PREFIX: Final[str] = "optik_solved_input"
# Directory for temporary contract binaries to be stored for processing
TMP_CONTRACT_DIR: Final[str] = "/tmp/"


def translate_argument(arg: Dict) -> Tuple[str, Union[bytes, int, Value]]:
    """Translate a parsed Echidna transaction argument into a '(type, value)' tuple.
    :param arg: Transaction argument parsed as a json dict"""
    argType = arg["tag"]
    if argType == "AbiUInt":
        bits = arg["contents"][0]
        val = int(arg["contents"][1])
        return (
            f"uint{bits}",
            val,
        )
    elif argType == "AbiInt":
        bits = arg["contents"][0]
        val = int(arg["contents"][1])
        return (f"int{bits}", val)

    elif argType == "AbiAddress":
        val = int(arg["contents"], 16)
        return (
            f"address",
            val,
        )
    elif argType == "AbiBool":
        val = arg["contents"]
        return (
            f"bool",
            val,
        )
    else:
        raise EchidnaException(f"Unsupported argument type: {argType}")


def load_tx(tx: Dict, tx_name: str = "") -> AbstractTx:
    """Translates a parsed echidna transaction into a Maat transaction

    :param tx: Echidna transaction parsed as a json dict
    :param tx_name: Optional name identifying this transaction, used to
        name symbolic variables created to fill the transaction data
    """
    # Translate function call and argument types and values
    call = tx["_call"]
    if call["tag"] != "SolCall":
        raise EchidnaException(f"Unsupported transaction type: '{call['tag']}'")

    arg_types = []
    arg_values = []
    func_name = call["contents"][0]
    if len(call["contents"]) > 1:
        for arg in call["contents"][1]:
            t, val = translate_argument(arg)
            arg_types.append(t)
            arg_values.append(val)

    func_signature = f"({','.join(arg_types)})"
    ctx = VarContext()
    call_data = function_call(
        func_name, func_signature, ctx, tx_name, *arg_values
    )

    # Translate block number/timestamp increments
    block_num_inc = Var(256, f"{tx_name}_block_num_inc")
    block_timestamp_inc = Var(256, f"{tx_name}_block_timestamp_inc")
    ctx.set(block_num_inc.name, int(tx["_delay"][1], 16), block_num_inc.size)
    ctx.set(
        block_timestamp_inc.name, int(tx["_delay"][0], 16), block_num_inc.size
    )

    # Translate message sender
    sender = Var(160, f"{tx_name}_sender")
    ctx.set(sender.name, int(tx["_src"], 16), sender.size)

    # Translate message value
    value = Var(256, f"{tx_name}_value")
    ctx.set(value.name, int(tx["_value"], 16), value.size)

    # Build transaction
    # TODO: correctly handle gas_limit
    # TODO: make EVMTransaction accept integers as arguments
    gas_limit = Cst(256, 46546514651)
    recipient = int(tx["_dst"], 16)
    return AbstractTx(
        EVMTransaction(
            sender,  # origin
            sender,  # sender
            recipient,  # recipient
            value,  # value
            call_data,  # data
            gas_limit,  # gas_limit
        ),
        block_num_inc,
        block_timestamp_inc,
        ctx,
    )


def load_tx_sequence(filename: str) -> List[AbstractTx]:
    """Load a sequence of transactions from an Echidna corpus file

    :param filename: corpus file to load
    """
    with open(filename, "rb") as f:
        data = json.loads(f.read())
        res = []
        for i, tx in enumerate(data):
            res.append(load_tx(tx, tx_name=f"tx{i}"))
        return res


def update_argument(arg: Dict, arg_name: str, new_model: VarContext) -> None:
    """Update an argument value in a transaction according to a
    symbolic model. The argument is modified **in-place**

    :param arg: argument to update, parsed as a JSON dict
    :param arg_name: base name of the symbolic variable that was created for this
    argument
    :param new_model: symbolic model to use to update the argument value
    """
    # Update the argument only if the model contains a new value
    # for this argument
    if not new_model.contains(arg_name):
        return

    argType = arg["tag"]
    if argType == "AbiUInt":
        arg["contents"][1] = str(new_model.get(arg_name))
    elif argType == "AbiInt":
        argVal = int(new_model.get(arg_name))
        bits = arg["contents"][0]
        arg["contents"][1] = str(twos_complement_convert(argVal, bits))
    elif argType == "AbiBool":
        argVal = new_model.get(arg_name)
        arg["contents"] = int_to_bool(argVal)
    elif argType == "AbiAddress":
        arg["contents"] = str(hex(new_model.get(arg_name)))
    else:
        raise EchidnaException(f"Unsupported argument type: {argType}")


def update_tx(tx: Dict, new_model: VarContext, tx_name: str = "") -> Dict:
    """Update parameter values in a transaction according to a
    symbolic model

    :param tx: Echidna transaction to update, parsed as a JSON dict
    :param new_model: symbolic model to use to update transaction data in 'tx'
    :param tx_name: Optional name identifying the transaction to update, used to
        name get symbolci variables corresponding to the transaction data. Needs
        to match the 'tx_name' passed to load_tx() earlier
    :return: the updated transaction as a JSON dict
    """
    tx = tx.copy()  # Copy transaction to avoid in-place modifications

    # Update call arguments
    call = tx["_call"]
    args = call["contents"][1]
    for i, arg in enumerate(args):
        update_argument(arg, f"{tx_name}_arg{i}", new_model)

    # Update block number & timestamp
    block_num_inc = f"{tx_name}_block_num_inc"
    block_timestamp_inc = f"{tx_name}_block_timestamp_inc"
    if new_model.contains(block_num_inc):
        tx["_delay"][1] = hex(new_model.get(block_num_inc))
    if new_model.contains(block_timestamp_inc):
        tx["_delay"][0] = hex(new_model.get(block_timestamp_inc))

    # Update sender
    sender = f"{tx_name}_sender"
    if new_model.contains(sender):
        # Address so we need to pad it to 40 chars (20bytes)
        tx["_src"] = f"0x{new_model.get(sender):0{40}x}"

    # Update transaction value
    value = f"{tx_name}_value"
    if new_model.contains(value):
        tx["_value"] = hex(new_model.get(value))

    return tx


def store_new_tx_sequence(original_file: str, new_model: VarContext) -> None:
    """Store a new sequence of transactions into a new Echidna corpus file

    :param original_file: path to the file containing the original transaction sequence
    that was replayed in order to find the new input
    :param new_model: symbolic context containing new values for the transaction data
    """
    # Load original JSON corpus input
    with open(original_file, "rb") as f:
        data = json.loads(f.read())

    # Update JSON with new transactions
    new_data = []
    for i, tx in enumerate(data):
        new_data.append(update_tx(tx, new_model, tx_name=f"tx{i}"))

    # Write new corpus input in a fresh file
    new_file = get_available_filename(
        f"{os.path.dirname(original_file)}/{NEW_INPUT_PREFIX}", ".txt"
    )
    with open(new_file, "w") as f:
        json.dump(new_data, f)


def get_available_filename(prefix: str, suffix: str) -> str:
    """Get an avaialble filename. The filename will have the
    form '<prefix>_<num><suffix>' where <num> is automatically
    generated based on existing files

    :param prefix: the new file prefix, including potential absolute the path
    :param suffix: the new file suffix
    """
    num = 0
    num_max = 100000
    while os.path.exists(f"{prefix}_{num}{suffix}") and num < num_max:
        num += 1
    if num >= num_max:
        raise GenericException("Can't find available filename, very odd")
    return f"{prefix}_{num}{suffix}"


# TODO(boyan): make this support multiple files/contracts
def extract_contract_bytecode(crytic_dir: str) -> str:
    """Parse compilation information from crytic, extracts the bytecode
    of a compiled contract, and stores it into a separate file
    WARNING: currently limited to fuzzing campaigns on a single contract file!

    :param crytic-dir: the "crytic-export" dir created by echidna after a campaign
    :return: file containing the bytecode of the contract
    """
    unique_signature = hex(random.getrandbits(32))[2:]
    output_file = str(
        os.path.join(TMP_CONTRACT_DIR, f"optik_contract_{unique_signature}.sol")
    )
    with open(str(os.path.join(crytic_dir, "combined_solc.json")), "rb") as f:
        data = json.loads(f.read())
        contract_name, contract_data = next(iter(data["contracts"].items()))
        bytecode = contract_data["bin"]
        with open(output_file, "w") as f2:
            f2.write(bytecode)
    return output_file
